# 日志篇

# why log important
我们通过日志来maintain 应用的健康，集群的健康，同时可以通过日志来解决应用的各种问题，提高用户体验性能

# 日志分类
## pod && container log
container logging主要是抓取stdout && stderr，可以通过`kubect log`命令简单的查看日志

不同的容器运行时是不同的方法去处理container stdout 跟stderr streams的

## system component log
### kubelet log
kubelet的日志通常我们可以使用`journalctl`来读取systemd journal
### scheduler. controller mgr, apoiserver
这三个一般以静态pod存在

## events
events的日志在pod启动或者部署应用排查问题的时候会经常用到，比如说用户pod被gatekeeper拦截
## audit log
audit log可以通过kube-apiserver的request
# 日志格式 log format

# k8s logging tools

## ELK
一般来说ELK我们都会加一个kafka, kafka能帮助我们削峰。ELK可以使用redis作为消息队列，但redis作为消息队列不是强项而且redis集群不如专业的消息发布系统kafka。

一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer。后续会结合Kafka讲一个企业级日志系统应用（每天20TB的数据量）。
* 消息系统：解耦和生产者和消费者、缓存消息等。
* 用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些* topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。
* 运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。
* 流式处理：比如spark streaming和storm
* 事件源
